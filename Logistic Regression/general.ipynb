{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ver001(x):\n",
    "    return [1/(1 + np.exp(-ele)) for ele in x]\n",
    "\n",
    "def Ver002(x):\n",
    "    return 1 / (1 + (np.exp(-x)))\n",
    "\n",
    "min_limit = 709\n",
    "def Ver003(x):\n",
    "    return 1 / (1 + np.exp(-(np.clip(x,-min_limit,None))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7310585786300049]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ver001([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ver002(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ver003([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a given numpy array to its sigmoid and its associated derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input array\n",
    "x = [[3, 1], [0, 4]] \n",
    "\n",
    "#Sample output\n",
    "# [[0.95 0.73]\n",
    "#  [0.5 0.98]] \n",
    "# [[0.05 0.2 ]\n",
    "#  [0.25 0.02]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95 0.73]\n",
      " [0.5  0.98]]\n",
      "[[0.05 0.2 ]\n",
      " [0.25 0.02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings as war\n",
    "war.filterwarnings('ignore')\n",
    "\n",
    "def sigmoid(x):\n",
    "    '''x is a list\n",
    "       Output -> Two numpy arrays are expected to be returned both with the same dimensions as of x'''\n",
    "    \n",
    "    x = np.asarray(x)\n",
    "\n",
    "    sigmoid  = 1 / (1 + (np.exp(-x)))\n",
    "    sigmoid_dev = sigmoid * (1 - sigmoid)\n",
    "    print(sigmoid.round(2))\n",
    "    print(sigmoid_dev.round(2))\n",
    "           \n",
    "#Driver function\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q) Log loss and derivative\n",
    "\n",
    "\n",
    "Problem Statement\n",
    "\n",
    "LogLoss is defined as: −y.log( \n",
    "y\n",
    "​\n",
    " )−(1−y).log(1− \n",
    "y\n",
    "​\n",
    " ),\n",
    "where y represents the true label and  \n",
    "y\n",
    "​\n",
    "  represents the probability output by logistic regression model.\n",
    "\n",
    "\n",
    "Problem Description:\n",
    "\n",
    "Given the true labels for the ith sample is y \n",
    "i\n",
    "​\n",
    "  and z \n",
    "i\n",
    "​\n",
    " =w \n",
    "0\n",
    "​\n",
    " +∑ \n",
    "j=1\n",
    "d\n",
    "​\n",
    " w \n",
    "j\n",
    "​\n",
    " ×x \n",
    "ij\n",
    "​\n",
    " , where:\n",
    "\n",
    "1. d is the number of features used\n",
    "\n",
    "2. w \n",
    "j\n",
    "​\n",
    "  is the jth value of the weight of the model\n",
    "\n",
    "3. x \n",
    "ij\n",
    "​\n",
    "  is the jth feature value of the ith sample\n",
    "\n",
    "\n",
    "\n",
    "Find and return the logLoss and the derivative of logLoss (w.r.t to the first feature) which is defined as:\n",
    "\n",
    "\n",
    "\n",
    "dwj/dL(w)  =(yi − yi))*(−xij)\n",
    "\n",
    "\n",
    "\n",
    "Note: The values in the arrays should be rounded up to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "z = [3.11, 0.08, 0.76, 5.98, 3.05, 0.12, 8.99, 1.69, 1.75, 1.54] \n",
    "y_true = [1, 0, 1, 0, 0, 0, 1, 1, 0, 1]  \n",
    "x = [[11, 22], [39, 0], [33, 39], [1, 28], [9, 24], [19, 14], [6, 7], [28, 3], [4, 17], [35, 15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.04, 0.73, 0.38, 5.98, 3.1 , 0.75, 0.  , 0.17, 1.91, 0.19]),\n",
       " array([ -0.47,  20.28, -10.52,   1.  ,   8.59,  10.07,  -0.  ,  -4.36,\n",
       "          3.41,  -6.18]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def logloss(z, y_true, x):\n",
    "    '''z, y_true and x are lists\n",
    "       output -> Two numpy arrays are expected to be returned'''\n",
    "    \n",
    "    z = np.asarray(z)\n",
    "    y_true = np.asarray(y_true)\n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "\n",
    "    y_hat = 1 / (1 + (np.exp(-z)))\n",
    "    #y_hat = y_hat.round(2)\n",
    "\n",
    "    logloss = (-1 * y_true * np.log(y_hat)) - ((1 - y_true) * np.log(1 - y_hat))\n",
    "    logloss = logloss.round(2)\n",
    "    \n",
    "    logloss_dev = (y_hat - y_true) * [x[0] for x in x]\n",
    "    logloss_dev = logloss_dev.round(2)\n",
    "\n",
    "    return logloss,logloss_dev\n",
    "\n",
    "\n",
    "\n",
    "logloss(z, y_true, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 39, 33, 1, 9, 19, 6, 28, 4, 35]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-879a04ce8a40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Description**\n",
    "\n",
    "Given train and test data in the form of lists as arguments of the function errors(), complete the function to return the lists train_errs and test_errs where train_err will consist of the errors in X_train for different values of C in the list c, and test_errs will have the errors for the test data.\n",
    " - ***C is basically a hyperparameter in the logistic regression model representing the reciprocal of regularization parameter λ. High values of C cause less regularization which leads the model to overfit on training data, whereas low values of C causes it to underfit.***\n",
    "\n",
    "Note: Here, by error we mean the percentage of misclassified points, converted to decimal.\n",
    "\n",
    "\n",
    "Sample Input:\n",
    "\n",
    "- X_train = [[93, 17], [83, 8], [80, 13], [15, 30], [63, 31], [11, 28], [73, 55], [82, 11], [50, 6], [2, 89]]\n",
    "- y_train = [0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
    "- X_test = [[9, 53], [6, 7], [21, 61], [65, 75], [48, 67]]\n",
    "- y_test = [0, 0, 1, 0, 0]\n",
    "- c = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "\n",
    "Sample Output:\n",
    "\n",
    "- train_errs = [0.2, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4]\n",
    "- test_errs = [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def training_errors(X_train, y_train, X_test, y_test,c):\n",
    "    ''' X_train, y_train, X_test, y_test,c are all in the form of lists\n",
    "        Output -> Two lists are expected to be returned'''\n",
    "    \n",
    "    #converting all the lists into Numpy arrays\n",
    "    X_train = np.asarray(X_train)  \n",
    "    X_test = np.asarray(X_test)  \n",
    "    y_train = np.asarray(y_train)  \n",
    "    y_test = np.asarray(y_test)  \n",
    "    train_errs = list()\n",
    "    test_errs = list()\n",
    "    \n",
    "    for c_value in c:\n",
    "        #initialize the logistic regression model\n",
    "        clf = LogisticRegression(C=c_value)\n",
    "        \n",
    "        #fit the training data on the model\n",
    "        clf.fit(X_train,y_train)\n",
    "\n",
    "        #y_pred_train = clf.predict(X_train)\n",
    "        train_score = clf.score(X_train,y_train)\n",
    "        test_score = clf.score(X_test,y_test)\n",
    "        \n",
    "        #append the errors for each value of C for train and test data.\n",
    "        train_errs.append(round( 1.0 - train_score, 2))\n",
    "        test_errs.append(round( 1.0 - test_score,2))\n",
    "    \n",
    "    return train_errs,test_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3], [0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [[44, 15],[75, 17],[30, 50],[41, 89],[15,3],[36,  7],[46, 22],[96, 13],[85,  5],[81, 35]]\n",
    "y_train = [1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
    "X_test = [[61, 64],[40, 91],[67, 22],[81, 13],[50, 85],[30, 49],[35, 10],[49, 76],[50, 65],[56,  2]]\n",
    "y_test = [0, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
    "c = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "\n",
    "training_errors(X_train, y_train, X_test, y_test,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Train and predict\n",
    "\n",
    "Problem Description\n",
    "\n",
    "Given the fixed acidity, volatile acidity, and residual sugar levels of certain wine samples, predict whether these wine samples are of good or bad quality (Good being y=1 and bad being y=0). Complete the function predict_class(), using the X_train, y_train, and X_test for returning the predictions of wine samples in the X_test.\n",
    "\n",
    "Instructions:\n",
    "1. Import the logistic regression model\n",
    "2. Train the Logistic Regression model on the training data.\n",
    "3. Predict the classes of the observations present in the test data (X_test).\n",
    "4. Return the NumPy array of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[44, 20, 5], [53, 44, 42], [71, 82, 18], [84, 67, 69], [79, 55, 1], [5, 97, 79], [73, 51, 60], [95, 45, 69], [79, 3, 64], [56, 94, 50], [32, 60, 74], [21, 54, 23], [72, 1, 22], [96, 4, 92], [98, 74, 3]]\n",
    "y_train = [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1]\n",
    "X_test = [[94, 31, 74], [7, 48, 18], [19, 67, 18], [30, 88, 1], [87, 35, 36]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def predict_class(X_train, y_train, X_test):\n",
    "    '''X_train, y_train, X_test are all in the form of lists\n",
    "       Output -> A numpy array of class labels of the same length as of X_test is expected to be returned'''\n",
    "    \n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    \n",
    "    #initialize the logistic regression model\n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "    #fit the training data on the model\n",
    "    clf.fit(X_train,y_train)  \n",
    "    \n",
    "    #predict the labels of the observations in X_test\n",
    "    predictions = clf.predict(X_test)  \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Metrics-Accuracy\n",
    "\n",
    "Problem Description:\n",
    "\n",
    "Create a function that calculates accuracy for the given input arrays.\n",
    "\n",
    "Accuracy=  \n",
    "TotalPrediction\n",
    "CorrectPrediction\n",
    "\n",
    "Note: After Calculating the accuracy, multiply accuracy with 100 and print the output.\n",
    "Do not Use Scikit Learn Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = [1,0,2]\n",
    "predicted = [1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    accuracy = 0\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    count = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            count += 1\n",
    "    \n",
    "    accuracy = (count / len(actual)) * 100\n",
    "\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666666"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_metric(actual, predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under the Curve\n",
    "\n",
    "Calculate the AUC for the given inputs\n",
    "\n",
    "- probab = [0.64, 0.01, 0.22, 0.44, 0.02, 0.64, 0.87, 0. , 0.06, 0.8 ]\n",
    "- labels = [1, 0, 1, 1, 0, 0, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def au_roc(prob, labels):\n",
    "    \n",
    "    data = pd.DataFrame({\"probab\" : prob, \"y\" : labels})\n",
    "    \n",
    "    #storing all the threshold values sorted in descending order\n",
    "    thr=  list(set(data['probab']))\n",
    "    thr.sort(reverse = True)\n",
    "    \n",
    "    tpr_arr,fpr_arr = [],[]\n",
    "\n",
    "    for i in thr:\n",
    "        #adding new column y_pred based on probability score and threshold\n",
    "        data['y_pred'] = data['probab'].apply(lambda y_score: 0 if y_score < i else 1)\n",
    "        \n",
    "        #calculate true negatives, false positives, false negatives and true positives\n",
    "        tn = len(data[(data.y == 0) & (data.y_pred == 0)])\n",
    "        fp = len(data[(data.y== 0) & (data.y_pred == 1)])\n",
    "        fn = len(data[(data.y == 1) & (data.y_pred == 0)])\n",
    "        tp = len(data[(data.y == 1) & (data.y_pred == 1)])\n",
    "        \n",
    "        #calculate true positive rate and false positive rate\n",
    "        tpr = tp/(tp + fn)\n",
    "        fpr = fp/(tn + fp)\n",
    "        \n",
    "        tpr_arr.append(tpr)\n",
    "        fpr_arr.append(fpr)\n",
    "\n",
    "    \n",
    "    #Calculating the area under curve using trapz function\n",
    "    auroc = np.trapz(y = tpr_arr, x=fpr_arr)\n",
    "    print('tpr_array: ',tpr_arr)\n",
    "    print('fpr_array: ',fpr_arr)\n",
    "\n",
    "    return auroc.round(2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr_array:  [0.2, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8, 0.8, 1.0]\n",
      "fpr_array:  [0.0, 0.2, 0.4, 0.4, 0.4, 0.6, 0.8, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab = [0.64, 0.01, 0.22, 0.44, 0.02, 0.64, 0.87, 0. , 0.06, 0.8 ]\n",
    "#probab = np.sqrt(probab)\n",
    "labels = [1, 0, 1, 1, 0, 0, 1, 1, 0, 0]\n",
    "\n",
    "au_roc(probab, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr_array:  [0.2, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8, 0.8, 1.0]\n",
      "fpr_array:  [0.0, 0.2, 0.4, 0.4, 0.4, 0.6, 0.8, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probab = [0.64, 0.01, 0.22, 0.44, 0.02, 0.64, 0.87, 0. , 0.06, 0.8 ]\n",
    "probab = np.sqrt(probab)\n",
    "labels = [1, 0, 1, 1, 0, 0, 1, 1, 0, 0]\n",
    "\n",
    "au_roc(probab, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e287c795756e004cbc239a0cd2370360bfb1c5c74b3b718d3796ac64793fd0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

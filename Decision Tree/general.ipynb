{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculatng gini impurity\n",
    "\n",
    "def gini_impurity(y):\n",
    "    \n",
    "  if isinstance(y, pd.Series):\n",
    "    p = y.value_counts()/y.shape[0]\n",
    "    gini = 1-np.sum(p**2)\n",
    "    return gini\n",
    "\n",
    "  else:\n",
    "    raise('Object must be a Pandas Series.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series([0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_impurity(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us calculate the information gain for each attribuite and decide the splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = [0,0,0,1,0,1,1,1,1,1]\n",
    "\n",
    "attr1 = [1,1,1,1,1,0,0,0,1,1]\n",
    "attr2 = [0,1,1,0,1,0,0,0,1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr1 = np.asarray(attr1)\n",
    "attr2 = np.asarray(attr2)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[attr1 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "\n",
    "    # calculating probability\n",
    "    y = pd.Series(y)\n",
    "    p = y.value_counts()/y.shape[0]\n",
    "    \n",
    "    entropy = np.sum(-p*np.log2(p+1e-9)) # adding delta 1e-9 in case p = 0 as log(0) is not defined\n",
    "\n",
    "    return(entropy)\n",
    "\n",
    "def find_attr(attr1, attr2, y):\n",
    "    '''\n",
    "    attr1 : Attribute1\n",
    "    attr2: Attribute2\n",
    "    y: The class labels\n",
    "\n",
    "    '''\n",
    "    attr1 = np.asarray(attr1)\n",
    "    attr2 = np.asarray(attr2)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    #calculate the entropy of the parent node\n",
    "    par_entropy = entropy(y)\n",
    "    \n",
    "    m = len(y)\n",
    "\n",
    "    #if we split using the attr1\n",
    "    y_10 = y[attr1 == 0]  #this node consists of all the observations where attr1 has value 0\n",
    "    entr_10 = entropy(y_10)\n",
    "    y_11 = y[attr1 == 1]  #this node consists of all the observations where attr1 has value 1\n",
    "    entr_11 = entropy(y_11)\n",
    "    y_12 = y[attr1 == 2]  #this node consists of all the observations where attr1 has value 2\n",
    "    entr_12 = entropy(y_12)\n",
    "\n",
    "   #Calculate the information gain for attribute 1\n",
    "    info_gain_1 = par_entropy - ((y_10.shape[0]/y.shape[0] * entr_10) + (y_11.shape[0]/y.shape[0] * entr_11) + (y_12.shape[0]/y.shape[0] * entr_12))   #y_category.shape[0]/y.shape[0]*entropy_category\n",
    "    info_gain_1 = np.round(info_gain_1, 2)\n",
    "\n",
    "    #if we split using the attr2\n",
    "    y_20 = y[attr2 == 0]  #this node consists of all the observations where attr2 has value 0\n",
    "    entr_20 = entropy(y_20)\n",
    "    y_21 = y[attr2 == 1]  #this node consists of all the observations where attr1 has value 1\n",
    "    entr_21 = entropy(y_21)\n",
    "\n",
    "    #Calculate the information gain for attribute 2\n",
    "    info_gain_2 = par_entropy - ((y_20.shape[0]/y.shape[0] * entr_20) + (y_21.shape[0]/y.shape[0] * entr_21) )\n",
    "    info_gain_2 = np.round(info_gain_2, 2)\n",
    "\n",
    "    #return the attribute name along with corresponding info_gain for which information gain is higher if used in splitting \n",
    "    return (\"attribute1\", info_gain_1) if info_gain_1 > info_gain_2 else (\"attribute2\", info_gain_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505915692787"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4426951595367387e-09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_10 = y[attr1 == 0]  #this node consists of all the observations where attr1 has value 0\n",
    "entr_10 = entropy(y_10)\n",
    "entr_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('attribute1', 0.28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_attr(attr1, attr2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_20 = y[attr2 == 0]  #this node consists of all the observations where attr2 has value 0\n",
    "entr_20 = entropy(y_20)\n",
    "y_21 = y[attr2 == 1]  #this node consists of all the observations where attr1 has value 1\n",
    "entr_21 = entropy(y_21)\n",
    "\n",
    "#Calculate the information gain for attribute 2\n",
    "info_gain_2 = entropy(y) - ((y_20.shape[0]/y.shape[0] * entr_20) + (y_20.shape[0]/y.shape[0] * entr_21) )\n",
    "info_gain_2 = np.round(info_gain_2, 2)\n",
    "\n",
    "info_gain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F= 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "y_true = [0,0,0,0,0,1,1,1,1,1]\n",
    "y_pred = [1,1,1,1,1,1,1,1,1,1]\n",
    "f= fbeta_score(y_true, y_pred, beta = 0.5)\n",
    "print('F=', f.round(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Decision Tree Regression\n",
    "- As you know, a Decision Tree is all about splitting nodes at different levels and trying to do predictions accurately.\n",
    "- Given features and labels/targets, determine which feature is best to split upon at the first root level for building a decision tree.\n",
    "- Note : The features are binary(containing 0 or 1 only) whereas targets are continuous in nature (regression).\n",
    "- So, the main task is to determine which attribute/feature is best to split upon considering the regression task taking the loss as \"Residual sum of squares\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inputs \n",
    "features: np.array([[1, 1],[0, 1],[1, 1],[1, 1],[0, 1],[0, 0],[1, 1],[0, 0],[1, 0],[1, 1]])\n",
    "targets: np.array([ 1.02721641, -0.25072461, -1.56434949,  1.15213561,  1.34919707,-1.35253951, -0.17552063, -0.45909391, -0.10864444,  0.83352153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(features, targets):\n",
    "    '''\n",
    "    inputs:\n",
    "        features: nd-array\n",
    "        labels: nd-array\n",
    "    output:\n",
    "        integer value determining best attribute idx (1-based indexing) for decision tree regression\n",
    "    '''\n",
    "\n",
    "    best_feature_idx = None\n",
    "    best_value = None\n",
    "    mse_base = 1e9\n",
    "    \n",
    "    #iterating through each of the feature\n",
    "    for feature_idx in range(features.shape[1]):\n",
    "        # Observations in left and right of the node\n",
    "        left_y = ___________  #left node will have all the target values of observations in which feature_idxth feature is 0\n",
    "        right_y = ___________ #left node will have all the target values of observations in which feature_idxth feature is 1\n",
    "    \n",
    "            \n",
    "        # calculate the means \n",
    "        left_mean = _________\n",
    "        right_mean = _________\n",
    "        \n",
    "        # calculate the left and right residuals \n",
    "        res_left = __________\n",
    "        res_right = ___________\n",
    "        \n",
    "        # Calculate the mse \n",
    "        #YOUR CODE GOES HERE\n",
    "        \n",
    "        \n",
    "        \n",
    "        #YOUR CODE ENDS HERE\n",
    "        # Checking if this is the best split so far \n",
    "        if mse_split < mse_base:\n",
    "            best_feature_idx = feature_idx\n",
    "    \n",
    "            # Setting the best gain to the current one \n",
    "            mse_base = mse_split\n",
    "    return best_feature_idx+1 # For 1-based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging\n",
    "\n",
    "Given the training data, testing data, max_depth, n_trees, and ratio, you need to implement bagging. Return the predictions for the observations in the test data.\n",
    "A subsample(dataset, ratio) is implemented in the backend which returns a 2D list consisting of sampled observations from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[-0.049754741299329164, 1.7545324153602802, -2.015451904277496, -0.6655946053274271, 1.7654623717757776, 0.0], [-0.870176558754425, -0.8632506160200222, 1.0363347961933609, -0.9921482916137182, -1.1832955643653762, 1.0], [-0.5129465077761397, -1.2734979390270784, 1.0392261463425687, 0.5032338839619092, -0.27021541668479643, 1.0], [-1.1259555456220574, -1.3824926465371696, -2.4659947360738013, -1.0063448217690898, 0.5301098720856643, 0.0], [1.3355396455376942, 0.4767704351913865, -0.30995179013581164, 0.47754374871627314, 1.0282482787129177, 0.0], [-0.7941311111136664, -0.888479087765921, -0.9250860232848708, 1.7103333917320582, -0.006363196215441307, 0.0], [0.9640563948034004, 1.4206857618787228, -1.6719701692403608, -0.3025879352391404, -0.3062031013690185, 0.0], [2.1330018022897006, -0.2530885153742814, 0.14824433392167236, -1.5377998003498103, 1.491748723938095, 0.0], [0.8568323473193591, 1.454906042604595, 1.0226070656111748, 1.4208697842258664, -0.27155848114641123, 1.0], [-1.1103222963405424, -0.13362863845048603, 0.5522979973275985, 0.42165872702810914, 0.4884106152343072, 0.0]]\n",
    "test = [[0.17633958605089237, 0.35362499501406774, 1.0412089882932318, -0.7965536407430361, 0.9519863722017938], [0.620158792718217, 1.7453802356037476, 0.2816748822184669, -0.9782700792376439, -0.7872827938664166], [-1.306157556172553, -0.36060622411280663, 0.9397657677158866, -0.1262661498810779, -0.458138342833524], [-1.3391549838490366, 0.9327917466845197, 1.1026267285716564, 0.23785062696034148, -0.4146697234931255], [0.08239261344402903, 0.6390284651763855, 0.9943395785869232, -1.5238363086071611, -0.5068234330383359], [1.2456200894224607, -1.2782333788330993, -0.9217918528513316, 1.6251354644171232, -0.6064346799018023], [-0.2632339135609847, -1.086878071181507, -1.7763680131285988, 0.4366870243082978, 1.7860028809138975], [-0.9190320708567004, 0.6107324610184034, 0.9930674674619598, 1.353023555031771, -1.800699232148709], [0.9540368382685985, -1.227571715875412, -0.18990171035397174, -0.5446964612387463, 0.3511497213610034], [1.8860175589060588, -0.036958602806592036, -1.2247513223969646, 0.7340332381471137, 1.1319547973555735]]\n",
    "max_depth = 1\n",
    "n_trees = 3\n",
    "ratio = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Output\n",
    "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "np.random.seed(0)\n",
    "\n",
    "# train = np.asarray(eval(input()))\n",
    "# test = np.asarray(eval(input()))\n",
    "# max_depth = int(input()) #maximum depth of trees\n",
    "# n_trees = int(input()) #number of trees\n",
    "# ratio = float(input()) #ratio of length of dataset to be generated while sampling\n",
    "\n",
    "#Construct a tree model with max_depth = \"max_depth\", train it on the sample and return the model\n",
    "def build_tree(sample, max_depth):\n",
    "\ttree = DecisionTreeClassifier(max_depth = max_depth)\n",
    "\ttree.fit(sample)\n",
    "\treturn tree\n",
    "\n",
    "\n",
    "def bagging_predict(trees, row):\n",
    "    #predictions is the list of labels predicted by all the trees\n",
    "\tpredictions = [tree.predict(row.reshape(1,-1))[0] for tree in trees]\n",
    "\t\n",
    "\t#return the prediction according to procedure used in bagging in classification\n",
    "\treturn max(predictions, key = _______)\n",
    " \n",
    "#bagging\n",
    "def bagging(train, test, max_depth, n_trees, ratio):\n",
    "\ttrees = list()\n",
    "\tfor i in range(n_trees):\n",
    "\t\tsample = subsample(train, ratio) #A sample created from dataset of size round(len(dataset) * ratio)\n",
    "\t\ttree = build_tree(sample, max_depth)\n",
    "\t\ttrees.append(tree)\n",
    "\t\n",
    "\t#store the predictions for each observation in the test data\n",
    "\tpredictions = [_________________]\n",
    "\treturn(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-fb413202718f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-2d7eedc720ee>\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(sample, max_depth)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "build_tree((train,,max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis = [1, 1, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(max([str(i) for i in lis], key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    y_train.append(train[i][-1])\n",
    "    X_train.append(train[i][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1103223 , -0.13362864,  0.552298  ,  0.42165873,  0.48841062,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
    "b = ['c', 'b', 'c', 'c', 'b', 'c', 'a', 'a', 'a', 'b']\n",
    "c = [0, 0, 1, 1, 1, 1, 0, 1, 1, 0]\n",
    "d = [1, 1, 0, 1, 1]\n",
    "e = ['a', 'c', 'b', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# a = eval(input())\n",
    "# b = eval(input())\n",
    "# c = eval(input())\n",
    "# d = eval(input())\n",
    "# e = eval(input())\n",
    "\n",
    "train = pd.DataFrame({'attr1': a, 'attr2': b, 'tar': c})\n",
    "test = pd.DataFrame({'attr1': d, 'attr2': e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    0\n",
       "7    0\n",
       "8    1\n",
       "9    1\n",
       "Name: attr1, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['attr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    0\n",
       "7    1\n",
       "8    1\n",
       "9    0\n",
       "Name: tar, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr1</th>\n",
       "      <th>attr2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attr1 attr2\n",
       "0      1     a\n",
       "1      1     c\n",
       "2      0     b\n",
       "3      1     a\n",
       "4      1     b"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_int(dataset, column):\n",
    "    \n",
    "    #all the unique values in the the attr2\n",
    "\tunique = sorted(pd.Series(dataset['attr2']))\n",
    "\tprint(unique)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\t\n",
    "\t#replace the values in attr2\n",
    "\t#dataset = dataset.replace({\"attr2\": lookup})\n",
    "\treturn lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'c']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'b': 5, 'c': 9}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_column_to_int(train, 'attr2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    c\n",
       "1    b\n",
       "2    c\n",
       "3    c\n",
       "4    b\n",
       "5    c\n",
       "6    a\n",
       "7    a\n",
       "8    a\n",
       "9    b\n",
       "Name: attr2, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['attr2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "lookup = {}\n",
    "for i,letter in enumerate(string.ascii_lowercase):\n",
    "    lookup[letter] = i\n",
    "\n",
    "print(lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e287c795756e004cbc239a0cd2370360bfb1c5c74b3b718d3796ac64793fd0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

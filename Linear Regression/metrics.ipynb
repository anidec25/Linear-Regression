{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression models are commonly evaluated using various metrics to assess their performance and measure the quality of the predictions. Here are some common evaluation metrics for linear regression:\n",
    "\n",
    "Mean Squared Error (MSE): MSE is one of the most widely used metrics for regression problems. It calculates the average squared difference between the predicted and actual values. A lower MSE indicates better model performance.\n",
    "\n",
    "Root Mean Squared Error (RMSE): RMSE is the square root of the MSE. It provides a measure of the average magnitude of the residuals. Like MSE, a lower RMSE indicates better model performance.\n",
    "\n",
    "Mean Absolute Error (MAE): MAE measures the average absolute difference between the predicted and actual values. It provides a more interpretable metric as it represents the average magnitude of the residuals. Lower MAE indicates better model performance.\n",
    "\n",
    "R-squared (R^2) Score: R-squared is a statistical measure that represents the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features). It ranges from 0 to 1, where a higher value indicates a better fit. However, R-squared alone does not account for the complexity of the model.\n",
    "\n",
    "Adjusted R-squared: Adjusted R-squared is an adjusted version of the R-squared metric that considers the number of predictors in the model. It penalizes the addition of unnecessary predictors, helping to prevent overfitting.\n",
    "\n",
    "Mean Percentage Error (MPE): MPE calculates the average percentage difference between the predicted and actual values. It provides insights into the direction and magnitude of the errors.\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE): MAPE calculates the average percentage difference between the predicted and actual values, considering the absolute value of the errors. It is a commonly used metric for evaluating forecasting models.\n",
    "\n",
    "Residual Analysis: In addition to the above metrics, analyzing the residuals (the differences between predicted and actual values) is essential to understand the model's performance. Visualizing the residuals through scatter plots, histograms, or Q-Q plots can reveal patterns, heteroscedasticity, or other issues.\n",
    "\n",
    "It's important to choose evaluation metrics that align with the specific problem and requirements. Some metrics may be more suitable depending on the nature of the data and the goals of the analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "y_pred = [2, 1, 3, 1, 2, 3, 3, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "\n",
    "    \"\"\"\n",
    "    This function calculates mae\n",
    "    :param y_true: list of real numbers , true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean absolute error\n",
    "    \"\"\"\n",
    "\n",
    "    error = 0\n",
    "\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        error += np.abs(yt - yp)\n",
    "    \n",
    "    return error/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error Using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates MSE\n",
    "    :param y-true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: mean squared error\n",
    "    \"\"\"\n",
    "    error = 0\n",
    "\n",
    "    for yt,yp in zip(y_true,y_pred):\n",
    "        error += (yt-yp) ** 2\n",
    "\n",
    "    return error/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates r-squared score\n",
    "    :param y_true: list of real numbers, true values\n",
    "    :param y_pred: list of real numbers, predicted values\n",
    "    :return: r2 score\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the mean value of true values\n",
    "    mean_true_value = np.mean(y_true)\n",
    "\n",
    "    # initialize numerator with 0\n",
    "    numerator = 0\n",
    "    # initialize denominator with 0\n",
    "    denominator = 0\n",
    "\n",
    "    # loop over all true and predicted values\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # update numerator\n",
    "        numerator += (yt - yp) ** 2\n",
    "        # update denominator\n",
    "        denominator += (yt - mean_true_value) ** 2\n",
    "        # calculate the ratio\n",
    "        ratio = numerator / denominator\n",
    "        # return 1 - ratio\n",
    "    return 1 - ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.33333333333333326"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a812c55bce3c407bf29cdfef5b6aac384d8b6347ace0878b4444009fcafd7071"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e287c795756e004cbc239a0cd2370360bfb1c5c74b3b718d3796ac64793fd0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is regularization?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization is a technique used in machine learning to prevent overfitting and improve the generalization ability of a model. Overfitting occurs when a model fits the training data too closely, capturing not only the underlying patterns but also the noise and random fluctuations present in the data. As a result, the overfitted model performs well on the training data but fails to generalize well to new, unseen data.\n",
    "\n",
    "Regularization introduces additional constraints or penalties to the learning algorithm to discourage complex or extreme models that fit the noise in the training data. By imposing these constraints, regularization helps to simplify the model and reduce its reliance on the training data's specific noise. This encourages the model to learn the underlying patterns and generalize better to new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different types of regularization techniques used in machine learning:\n",
    "\n",
    "L1 Regularization (Lasso): L1 regularization adds a penalty term to the loss function that is proportional to the absolute value of the model's coefficients. It encourages sparsity by shrinking some coefficients to zero, effectively performing feature selection and reducing the model's complexity.\n",
    "\n",
    "L2 Regularization (Ridge): L2 regularization adds a penalty term to the loss function that is proportional to the squared magnitude of the model's coefficients. It discourages large coefficient values and encourages smaller and more evenly distributed coefficients. L2 regularization is particularly effective at reducing the impact of outliers.\n",
    "\n",
    "Elastic Net Regularization: Elastic Net combines L1 and L2 regularization by adding both penalty terms to the loss function. It allows for a balance between sparsity (L1) and ridge-like regularization (L2). Elastic Net is useful when there are many correlated features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of regularization technique depends on the problem, the dataset, and the specific learning algorithm being used. By applying regularization, machine learning models can achieve better generalization, improved performance on unseen data, and reduced overfitting, leading to more reliable and robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic dataset for regression\n",
    "X, y = make_regression(n_samples=100, n_features=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_regularization(reg_type):\n",
    "    if reg_type == 'Lasso':\n",
    "        model = Lasso(alpha=0.1)  # Adjust the alpha value for regularization strength\n",
    "    elif reg_type == 'Ridge':\n",
    "        model = Ridge(alpha=1.0)  # Adjust the alpha value for regularization strength\n",
    "    elif reg_type == 'ElasticNet':\n",
    "        model = ElasticNet(alpha=0.5, l1_ratio=0.5)  # Adjust the alpha and l1_ratio values\n",
    "    else:\n",
    "        raise ValueError(\"Invalid regularization type.\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{reg_type} MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso MSE: 0.0976520742153871\n",
      "Ridge MSE: 5.417352880125903\n",
      "ElasticNet MSE: 1437.2431828596618\n"
     ]
    }
   ],
   "source": [
    "# Apply Lasso regularization\n",
    "apply_regularization('Lasso')\n",
    "\n",
    "# Apply Ridge regularization\n",
    "apply_regularization('Ridge')\n",
    "\n",
    "# Apply Elastic Net regularization\n",
    "apply_regularization('ElasticNet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
